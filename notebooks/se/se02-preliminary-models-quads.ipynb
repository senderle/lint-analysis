{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.style.use('seaborn-muted')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import os\n",
    "import ujson\n",
    "import attr\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from glob import glob\n",
    "from collections import Counter, UserDict\n",
    "from itertools import islice\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading .npz vectors, metadata, and terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_npz = '../counts/novels.100.npz'\n",
    "\n",
    "def load_all_counts(path):\n",
    "    files = [os.path.join(path, f) \n",
    "             for f in os.listdir(path) \n",
    "             if f.endswith('.npz')]\n",
    "    collected = {}\n",
    "    for f in files:\n",
    "        collected.update(np.load(f))\n",
    "    return collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv('../metadata/novels-metadata.csv',\n",
    "                 index_col='identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Dataset:\n",
    "    \n",
    "    root = attr.ib()\n",
    "    \n",
    "    def paths(self):\n",
    "        return glob(os.path.join(self.root, '*.bz2'))\n",
    "    \n",
    "    def novels(self):\n",
    "        for path in tqdm_notebook(self.paths()):\n",
    "            with bz2.open(path) as fh:\n",
    "                for line in fh:\n",
    "                    yield ujson.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset('../data/top200-3bins.json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059ce820ceb84b43bc1b94709907729f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "novels = list(ds.novels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tercile_to_quad(terciles, feature):\n",
    "    t = terciles[feature]\n",
    "    return (t[0] < t[1]) + 2 * (t[1] < t[2]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = sorted(novels[0]['counts'].keys())\n",
    "terciles = {(f, i): {n['identifier']: n['counts'][f][i] for n in novels}\n",
    "            for f in feature_set for i in range(3)}\n",
    "terciles = pd.DataFrame(terciles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad = tercile_to_quad(terciles, 'a')\n",
    "md = md.loc[quad.index].assign(quad=quad)\n",
    "works_available = set(md_tags.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load_all_counts(count_npz)\n",
    "features = {k: v for k, v in features.items() if k in works_available}\n",
    "features = pd.DataFrame(features).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a cross-validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_sel, = (md['quad'] == 0).values.nonzero()\n",
    "q1_sel, = (md['quad'] == 1).values.nonzero()\n",
    "q2_sel, = (md['quad'] == 2).values.nonzero()\n",
    "q3_sel, = (md['quad'] == 3).values.nonzero()\n",
    "min_samples = min([len(s) for s in (q0_sel, q1_sel, q2_sel, q3_sel)])  # about 1500\n",
    "n_cv_samples = 4000\n",
    "np.random.seed(1000)\n",
    "np.random.shuffle(q0_sel)\n",
    "np.random.shuffle(q1_sel)\n",
    "np.random.shuffle(q2_sel)\n",
    "np.random.shuffle(q3_sel)\n",
    "cvdata = np.hstack([q0_sel[0:n_cv_samples // 4], \n",
    "                    q1_sel[0:n_cv_samples // 4],\n",
    "                    q2_sel[0:n_cv_samples // 4],\n",
    "                    q3_sel[0:n_cv_samples // 4],\n",
    "                   ])\n",
    "np.random.shuffle(cvdata)\n",
    "cvdata_md = md.iloc[cvdata]\n",
    "cvdata_features = features.iloc[cvdata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression (easy test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_train = len(cvdata_features) // 4 * 3\n",
    "predict_key = 'corpus'\n",
    "predict_val = 'chicago'\n",
    "\n",
    "X = cvdata_features.iloc[:n_train].values[:, :n_features]\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "y = (cvdata_md.iloc[:n_train][predict_key] == predict_val).values.astype(float)\n",
    "X_test = cvdata_features.iloc[n_train:].values[:, :n_features]\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "y_test = (cvdata_md.iloc[n_train:][predict_key] == predict_val).values.astype(float)\n",
    "\n",
    "lr = LogisticRegression(C=1.0)\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression (real test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.285"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_train = len(cvdata_features) // 4 * 3\n",
    "predict_key = 'quad'\n",
    "predict_val = 0\n",
    "\n",
    "X = cvdata_features.iloc[:n_train].values[:, :n_features]\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "y = (cvdata_md.iloc[:n_train][predict_key]).values.astype(int)       # == predict_val).values.astype(float)\n",
    "X_test = cvdata_features.iloc[n_train:].values[:, :n_features]\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "y_test = (cvdata_md.iloc[n_train:][predict_key]).values.astype(int)  # == predict_val).values.astype(float)\n",
    "\n",
    "lr = LogisticRegression(C=0.3)\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB (easy test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_train = len(cvdata_features) // 4 * 3\n",
    "predict_key = 'corpus'\n",
    "predict_val = 'chicago'\n",
    "\n",
    "X = cvdata_features.iloc[:n_train].values[:, :n_features]\n",
    "y = (cvdata_md.iloc[:n_train][predict_key] == predict_val).values.astype(float)\n",
    "X_test = cvdata_features.iloc[n_train:].values[:, :n_features]\n",
    "y_test = (cvdata_md.iloc[n_train:][predict_key] == predict_val).values.astype(float)\n",
    "\n",
    "lr = MultinomialNB()\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB (real test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.298"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_train = len(cvdata_features) // 4 * 3\n",
    "predict_key = 'quad'\n",
    "predict_val = 0\n",
    "\n",
    "X = cvdata_features.iloc[:n_train].values[:, :n_features]\n",
    "y = (cvdata_md.iloc[:n_train][predict_key]).values.astype(int)       # == predict_val).values.astype(float)\n",
    "X_test = cvdata_features.iloc[n_train:].values[:, :n_features]\n",
    "y_test = (cvdata_md.iloc[n_train:][predict_key]).values.astype(int)  # == predict_val).values.astype(float)\n",
    "\n",
    "lr = MultinomialNB()\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machine (easy test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_train = len(cvdata_features) // 4 * 3\n",
    "predict_key = 'corpus'\n",
    "predict_val = 'chicago'\n",
    "\n",
    "X = cvdata_features.iloc[:n_train].values[:, :n_features]\n",
    "y = (cvdata_md.iloc[:n_train][predict_key] == predict_val).values.astype(float)\n",
    "X_test = cvdata_features.iloc[n_train:].values[:, :n_features]\n",
    "y_test = (cvdata_md.iloc[n_train:][predict_key] == predict_val).values.astype(float)\n",
    "\n",
    "lr = SVC(C=1.0)\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machine (real test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.296"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_train = len(cvdata_features) // 4 * 3\n",
    "predict_key = 'quad'\n",
    "\n",
    "X = cvdata_features.iloc[:n_train].values[:, :n_features]\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "y = (cvdata_md.iloc[:n_train][predict_key]).values.astype(int)\n",
    "X_test = cvdata_features.iloc[n_train:].values[:, :n_features]\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "y_test = (cvdata_md.iloc[n_train:][predict_key]).values.astype(int)\n",
    "\n",
    "lr = SVC(C=1.0)\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
